%---------------------------------------------------------------------
%
%                          Conclusiones
%
%---------------------------------------------------------------------

\chapter{Conclusiones}
\label{capConclusiones}
En este trabajo de tesis se analizó cuanta información acerca de un estímulo auditivo (previamente presentado) hay contenida en los trenes de \glslink{PAN}{potenciales de acción} del \gls{VTA} y la \gls{PFC} del cerebro de la rata. El enfoque elegido consistió en el uso de \gls{CAA}, comparando la \gls{PDC} del Discriminante Lineal de Fisher (LDA), Bayes Naive, Máquinas de Soporte Vectorial (SVM) y Random Forest. En una primera aproximación, en la sección~\ref{capSetDeDatos:sec:features:subsec:monoNeuronal} se consideró a las neuronas registradas como independientes, donde sólo en pocos casos aislados, se obtuvo una \glssymbol{PDC} aceptable ($p<0.05$). Si un animal logra tasas de acierto mayores al 80\% es de suponer que, o bien se trata del consenso de un número grande de neuronas que individualmente aciertan, o es una propiedad emergente de una población que contribuye débilmente a un consenso fuerte en la decisión. Por este motivo se analizó la población de neuronas, para verificar si la interacción entre ellas brinda más información sobre el estímulo presentado que la suma de las contribuciones individuales. Los resultados obtenidos con los cuatro \glspl{MDC} empleados confirman esta suposición, la información codificada en la población de neuronas es mayor que la obtenida por contribuciones individuales, llegando a decodificar cual fue el estímulo presentado, aún 3 segundos después de su desaparición, con una tasa de acierto superior al 90\%.\\

Con el objetivo de estudiar la variabilidad de la \gls{PDC} en un análisis trial a trial, se implementó el método de \gls{Bs} y de esta forma se estimó el error estándar a la media. Con esta medida de variabilidad, se pudo analizar que tan buena es la clasificación de los estímulos para los cuatro métodos utilizados. En todos los casos SVM y Random Forest presentaron mayor \gls{PDC} que LDA y Bayes Naive, a expensas de una mayor complejidad en el cálculo de la superficie que separa las clases.\\

Desde el punto de vista de la utilidad de los métodos, la eficiencia en la decodificación debe evaluarse como un compromiso entre la cantidad de neuronas y la cantidad de tiempo necesaria para asegurar una predicción.\\
La cantidad de neuronas que se pueden acceder desde un registro de \gls{E} profundos, depende principalmente del número de \gls{E} implantados. Aumentar dicho número acarrea dos problemas: el tamaño del implante crece según el número de \gls{E} y el sistema inmune reacciona al cuerpo extraño. En la sección~\ref{capResultados:sec:conjRed} se estudió el efecto que produce reducir el número de neuronas en el análisis. Si bien la \glslink{PDC}{performance en la decodificación} decrece, se pudo observar que con un 10\% de las neuronas del \glslink{VTA}{área VTA} (16 neuronas), la misma alcanza el 90\% (utilizando Random Forest). Para asegurar que este porcentaje no es simplemente el resultado del muestreo (dado que hay neuronas individuales cuya \glslink{PDC}{performance en la decodificación} es alta) se removieron del análisis las neuronas con \gls{PDC} mayor a 70\%, y el resultado no se alteró significativamente. Se puede concluir que el efecto poblacional potencia la decodificación aún en un tamaño de población pequeño, que ronda la decena de neuronas.\\

Una de las principales restricciones impuestas sobre un sistema de decodificación portátil y on-line es el consumo energético. Toda interfaz cerebro computadora debe estar alimentada por baterías y su autonomía está directamente ligada al peso e indirectamente relacionada con el consumo. Para reducir el consumo es necesario ahorrar en cómputo, esto se logra minimizando el número de canales que se analizan (número de \gls{E}) o minimizando el tiempo de análisis. En la sección~\ref{capResultados:sec:tamVen} se estudió como el tamaño de la ventana de decodificación altera la \gls{PDC} y se determinó que una ventana de tamaño $400 ms$ (a partir de la aparición del estímulo), es suficiente para lograr una \gls{PDC} promedio mayor a 80\%. Se comparó la \gls{PDC} de esta estrategia con la de ventana deslizante y se determinó que no fueron diferentes, concluyendo que es más eficiente trabajar con una ventana corta ($300 ms$) y no procesar al comienzo del estímulo para ahorrar recursos.\\

Finalmente, como resultado de este trabajo se ha determinado: Que \textit{Random Forest} es la herramienta que mejor decodifica la información contenida en un tren de \glslink{PAN}{potenciales de acción} para las áreas estudiadas en la mayoría de los casos; que el efecto poblacional tiene más información que la contenida en neuronas individuales; que hay un límite superior en el número de neuronas a partir del cual no se puede obtener más información; que también existe un límite inferior que ronda la decena de neuronas y permite decodificar con buena \gls{PDC} (90\%); que con ventanas temporales de aproximadamente $300 ms$ se pueden decodificar los estímulos, con un retardo máximo, que ronda los $300 ms$, después de la presentación del estímulo; que analizando solamente los $300 ms$ posteriores al tono, se puede predecir el comportamiento del animal (si sacará o no la lengua) antes que el mismo ocurra, con un 70\% de probabilidad de acierto.\\

Quedan como líneas futuras de investigación, el estudio más profundo de cómo los diferentes parámetros (Apéndice~\ref{apendiceConfiguracion}) que configuran los métodos más eficientes (\textit{SVM} y \textit{Random Forest}) impactan en la \glslink{PDC}{performance de decodificación} y la estimación del gasto energético necesario para decodificar instantáneamente esta información de manera portátil.