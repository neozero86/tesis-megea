%---------------------------------------------------------------------
%
%                          Conclusiones
%
%---------------------------------------------------------------------

\chapter{Conclusiones}
\label{capConclusiones}
En este trabajo de tesis se analizó cuanta información acerca de un estímulo auditivo (previamente presentado) hay contenida en los trenes de \glslink{PAN}{potenciales de acción} del Área Tegmental Ventral (VTA) y la Corteza PreFrontal (PFC) del cerebro de la rata. La aproximación se realizó mediante el uso de \gls{CAA}, y se comparó la performance del Discriminante Lineal de Fisher (LDA), Bayes Naive, Máquinas de Soporte Vectorial (SVM) y Random Forest. En una primera aproximación, en la sección~\ref{capSetDeDatos:sec:features:subsec:monoNeuronal} se consideró a las neuronas registradas como independientes, donde sólo en pocos casos aislados, se obtuvo una performance de clasificación aceptable ($p<0.05$). Si un animal logra tasas de acierto mayores al 80\% es de suponer que, o bien se trata del consenso de un número grande de neuronas que individualmente aciertan, o es una propiedad emergente de una población que contribuye débilmente a un consenso fuerte en la decisión. Por este motivo se analizó la población de neuronas, para verificar si la interacción entre ellas brinda más información sobre el estímulo presentado que la suma de las contribuciones individuales. Los resultados obtenidos con los cuatro métodos de clasificación empleados confirman esta suposición, la información codificada en la población de neuronas es mayor que la obtenida por contribuciones individuales, llegando a decodificar cual fue el estímulo presentado, aún 3 segundos después de su desaparición, con una tasa de acierto superior al 90\%.\\

Con el objetivo de estudiar la variabilidad de la performance en un análisis trial a trial, se implementó el método de \textit{bootstrapping} y de esta forma se estimó el error estándar a la media. Con esta medida de variabilidad, se pudo analizar que tan buena es la clasificación de los estímulos para los cuatro métodos utilizados. En todos los casos SVM y Random Forest tuvieron performances más altas que LDA y Bayes Naive, a expensas de una mayor complejidad en el cálculo de la superficie que separa las clases.\\

Desde el punto de vista de la utilidad de los métodos, la eficiencia en la decodificación debe evaluarse como un compromiso entre la cantidad de neuronas y la cantidad de tiempo necesaria para asegurar una predicción.\\
La cantidad de neuronas que se pueden acceder desde un registro de electrodos profundos, depende principalmente del número de electrodos implantados. Aumentar dicho número acarrea dos problemas: el tamaño del implante crece según el número de electrodos y el sistema inmune reacciona al cuerpo extraño. En la sección~\ref{capResultados:sec:conjRed} se estudió el efecto que produce reducir el número de neuronas en el análisis. Si bien la performance en la decodificación decrece, se pudo observar que con un 10\% de las neuronas (del área VTA), la misma ronda el 90\% (utilizando Random Forest). Para asegurar que este porcentaje no es simplemente el resultado del muestreo (dado que hay neuronas individuales cuya performance en la decodificación es alta) se removieron del análisis las neuronas con performance mayor a 70\%, y el resultado no se alteró significativamente. Se puede concluir que el efecto poblacional potencia la decodificación aún en un tamaño de población reducida (una decena de neuronas).\\

Una de las principales restricciones impuestas sobre un sistema de decodificación portátil y on-line es el consumo energético. Toda interfaz cerebro computadora debe estar alimentada por baterías y su autonomía está directamente ligada al peso e indirectamente relacionada con el consumo. Para reducir el consumo es necesario ahorrar en cómputo, esto se logra minimizando el número de canales que se analizan (número de electrodos) o minimizando el tiempo de análisis. En la sección~\ref{capResultados:sec:tamVen} se estudió como el tamaño de la ventana de decodificación altera la performance y se determinó que una ventana de tamaño $400 ms$ (a partir de la aparición del estímulo), es suficiente para lograr una performace promedio mayor a 80\%. Se comparó esta estrategia con la de ventana deslizante y se determinó que las respectivas performances no fueron diferentes, concluyendo que es más eficiente trabajar con una ventana corta ($300 ms$) y no procesar al comienzo del estímulo para ahorrar recursos.\\

Finalmente, como resultado de este trabajo se ha determinado: Cuál herramienta resulta más apropiada para decodificar la información contenida en un tren de \glslink{PAN}{potenciales de acción}; que el efecto poblacional tiene más información que la contenida en neuronas individuales; que hay un límite superior en el número de neuronas a partir del cual no se puede obtener más información; que también existe un límite inferior que ronda la decena de neuronas y permite decodificar con buena performance (90\%); que con ventanas temporales de aproximadamente $300 ms$ se pueden decodificar los estímulos, con un retardo máximo, que ronda los $300 ms$, después de la presentación del estímulo; que analizando solamente los $300 ms$ posteriores al tono, se puede predecir el comportamiento del animal (si sacará o no la lengua) antes que el mismo ocurra, con un 70\% de probabilidad de acierto.\\

Quedan como líneas futuras de investigación, el estudio más profundo de cómo los diferentes parámetros que configuran el método más eficiente (\textit{Random Forest}) impactan en la performance de decodificación y la estimación del gasto energético necesario para decodificar instantáneamente esta información de manera portátil.