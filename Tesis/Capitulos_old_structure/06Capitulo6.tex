%---------------------------------------------------------------------
%
%                          Capítulo 6
%
%---------------------------------------------------------------------

\chapter{Iteraciones y resultados}
\label{capIterResult}
	
\begin{resumen}
En vista de los resultados obtenidos, y con el objetivo de validar que el porcentaje hallado anteriormente no haya sido casualidad, se corrieron 500 iteraciones para cada ventana.
\end{resumen}
	

%-------------------------------------------------------------------
\section{Introducción}
%-------------------------------------------------------------------
\label{capIterResult:sec:introduccion}
Para cada ventana se creará la matriz $X$ y el vector $Y$ y luego se correrá el algoritmo de clasificación 500 veces generando $X_{RUN}$, $Y_{RUN}$, $X_{TEST}$ e $Y_{TEST}$ tomando los datos de forma aleatoria, con el objetivo de promediar y calcular el desvío estandar de la performace de clasificación.
\pagebreak
%------------------------------------------------------------------
\section{Análisis con LDA}
\label{capIterResult:sec:analisis con LDA}

De las 500 iteraciones realizadas, se graficó el promedio y el desvío estándar de la performance de clasificación en función del tiempo.

\figura{Bitmap/06/LDA_line_run}{width=1\linewidth}{capIterResult:fig:LDALineRun}%
{LDA - Performance en funcion del tiempo - Promedio de las 500 corridas}

Dado que tomamos 500 iteraciones y que la perfomance con su desvío estandar a partir de cierto instante nunca disminuye de un 70\%, podemos afirmar con toda seguridad que la información del tono se encuentra almacenada en las neuronas.\\
Se observa ademas que, desestimando algunas ventanas donde el desvio estandar cae, a partir del milisegundo $6000$ la performance con su desvio, se mantiene por encima del 80\%. 
\\\\
A continuación, se correrán el resto de los algoritmos de clasificación para intentar mejorar la performance obtenida.\\
\pagebreak
%------------------------------------------------------------------
\section{Análisis con Bayes-Naive}
\label{capIterResult:sec:Análisis con Bayes-Naive}

Se entrenó un calsificador Bayes-Naive con una distribución de datos multinomial, dado que esta distribución suele tener buenos resultados para características discretas. \\
La probabilidad a priori de las clases se configuro como ``empiricas'', es decir que la misma será igual a la frecuencia relativa de distribucion de cada clase.
\\
Al igual que con LDA y los demás algoritmos, se corrieron 500 iteraciones para luego tomar el promedio de la precisión y su desvío estandar. Se muestran a continuación los resultados graficados en función del tiempo.
\figura{Bitmap/06/BN_line_run}{width=1\linewidth}{capIterResult:fig:BNLineRun}%
{Bayes Naive - Performance en funcion del tiempo - Promedio de las 500 corridas}

Se puede apreciar como a partir del milisegundo $5000$ la performance con su desvio estandar nunca decae del 80\%. A su vez, a partir del milisegundo $6000$ se mantiene sobre el 90\%.
\pagebreak

\section{Análisis con SVM}
\label{capIterResult:sec:Análisis con SVM}

Se entrenó un clasificador SVM con una funcion de kernel lineal.\\ 

%Puede q false el parametro C

Se presentan, a continuación, los resultados de la performance de clasificación en función del tiempo.

\figura{Bitmap/06/SVM_line_run}{width=1\linewidth}{capIterResult:fig:SVMLineRun}%
{SVM - Performance en funcion del tiempo - Promedio de las 500 corridas}

En este caso a partir del milisegundo $5500$ la performance con su desvio estandar se mantiene sobre el 90\%, y a medida que el tiempo transcurre se obtienen valores casi perfectos. 

\pagebreak
%------------------------------------------------------------------
\section{Análisis con Random Forest}
\label{capIterResult:sec:Análisis con Random Forest}

Se entrenó un clasificador random forest con 300 árboles.
El mtry que indica el número máximo de variables en cada arbol se configuró en 12. El mismo se calculó como el piso de la raíz cuadrada de la cantidad de neuronas. Se aconseja calcular el mtry de esta forma por primera vez, y luego si fuera necesario ir variando el valor hasta obtener la mejor performance. % Fijarse si falta setear algun parametro
\\ 
Se muestran, entonces, los resultados obtenidos hallando el promedio y el desvío estandar de la performance en las 500 iteraciones.\\

\figura{Bitmap/06/RF_line_run}{width=1\linewidth}{capIterResult:fig:RFLineRun}%
{Random Forest - Performance en funcion del tiempo - Promedio de las 500 corridas}

En la figura~\ref{capIterResult:fig:RFLineRun} se observa que este metodo converge rapidamente a 100\% a partir del milisegundo $4000$. Ya desde el $5000$ la performance se mantiene por encima del 90\% y se incrementa llegando al 100\% y manteniendose estable durante casi todo el resto del tiempo.
\\\\
A simple vista parece ser Random Forest el metodo que mejor clasifica, seguido por SVM y Bayes Naive en ese order. En el capitulo siguiente se realizarán las comparaciones correspondientes entre los algoritmos, con el objetivo de encontrar el mejor clasificador para \textit {spikes}.  